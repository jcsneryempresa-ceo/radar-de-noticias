import os
import json
import streamlit as st
import feedparser
import pandas as pd
import datetime

# ---------- TEMAS (dicion√°rios de apoio) ----------
TEMAS = [
    "Pol√≠tica", "Economia", "Esporte", "Moda",
    "Cultura", "Educa√ß√£o", "Seguran√ßa", "Sa√∫de"
]

# Palavras-base por tema (voc√™ pode ajustar com o tempo)
TEMA_KEYWORDS = {
    "Pol√≠tica": ["governo", "congresso", "minist", "prefeit", "vereador", "deput", "senad", "elei", "partid", "gest√£o"],
    "Economia": ["infla√ß√£o", "juros", "mercado", "pib", "d√≥lar", "emprego", "renda", "invest", "tribut", "or√ßamento"],
    "Esporte": ["campeonato", "atleta", "time", "t√©cnico", "torneio", "gol", "jogo", "liga", "sele√ß√£o"],
    "Moda": ["cole√ß√£o", "tend√™ncia", "look", "desfile", "estilo", "marca", "fashion", "roupa", "acess√≥rio"],
    "Cultura": ["festival", "show", "cinema", "teatro", "m√∫sica", "arte", "exposi√ß√£o", "livro", "literatura"],
    "Educa√ß√£o": ["escola", "universidade", "enem", "ifrn", "aluno", "professor", "aula", "educa√ß√£o", "matr√≠cula"],
    "Seguran√ßa": ["pol√≠cia", "crime", "pris√£o", "roubo", "assalto", "opera√ß√£o", "viol√™ncia", "investiga√ß√£o", "suspeito"],
    "Sa√∫de": ["hospital", "vacina", "doen√ßa", "sus", "m√©dico", "sa√∫de", "tratamento", "paciente", "epidemia"]
}

USO_FILE = "uso_ia.json"
MAX_DIARIO = 3

def carregar_uso():
    try:
        with open(USO_FILE, "r") as f:
            return json.load(f)
    except:
        return {"data": str(datetime.date.today()), "contador": 0}

def salvar_uso(dados):
    with open(USO_FILE, "w") as f:
        json.dump(dados, f)

def verificar_limite_diario():
    uso = carregar_uso()
    hoje = str(datetime.date.today())

    if uso["data"] != hoje:
        uso = {"data": hoje, "contador": 0}
        salvar_uso(uso)

    return uso
from collections import Counter
from openai import OpenAI

st.set_page_config(page_title="Radar de Not√≠cias", layout="centered")

# ---------- PERFIL (carrega do JSON) ----------
PROFILE_FILE = "perfil.json"

def load_profile():
    try:
        with open(PROFILE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {
            "nome_portal": "Radar de Not√≠cias",
            "assinatura": "jcsnery.empresa",
            "estilo": "jornalistico",
            "intencao_comunicativa": "neutro",
            "tamanho_padrao": "medio",
            "linhas": 10
        }

def save_profile(p):
    with open(PROFILE_FILE, "w", encoding="utf-8") as f:
        json.dump(p, f, ensure_ascii=False, indent=2)

profile = load_profile()

# ---------- HEADER ----------
st.title("üì° Radar de Not√≠cias")
st.caption(f"{profile.get('nome_portal','')} ‚Ä¢ {profile.get('assinatura','')}")

tabs = st.tabs(["Identidade & Diretrizes", "Intelig√™ncia", "Produ√ß√£o"])

# ---------- CONFIG DEFAULTS ----------
sites_default = {
    "Tribuna do Norte": "https://tribunadonorte.com.br/feed/",
    "Agora RN": "https://agorarn.com.br/feed/",
    "GE RN": "https://ge.globo.com/rss/ge/rn/"
}

if "sites" not in st.session_state:
    st.session_state.sites = sites_default.copy()

if "palavras" not in st.session_state:
    st.session_state.palavras = {"RN": 3, "Natal": 2, "Parnamirim": 4, "esporte": 2, "amador": 5}

if "ultimo_df" not in st.session_state:
    st.session_state.ultimo_df = None

# ---------- TAB 1: PERFIL ----------
with tabs[0]:
    st.subheader("Identidade & Diretrizes")

    col1, col2 = st.columns(2)
    with col1:
        nome_portal = st.text_input("Nome do portal", value=profile.get("nome_portal", "Radar de Not√≠cias"))
        assinatura = st.text_input("Assinatura", value=profile.get("assinatura", "jcsnery.empresa"))
    with col2:
        estilo = st.selectbox(
            "Estilo de linguagem",
            ["jornalistico", "analitico", "didatico", "opinativo_leve", "jovem"],
            index=["jornalistico","analitico","didatico","opinativo_leve","jovem"].index(profile.get("estilo","jornalistico"))
        )
        linhas = st.slider("Quantidade de linhas (aprox.)", 4, 20, int(profile.get("linhas", 10)))

    intencao = st.text_area(
        "Inten√ß√£o comunicativa (o que voc√™ quer que o texto deixe claro)",
        value=profile.get("intencao_comunicativa", ""),
        height=90,
        placeholder="Ex.: contextualizar, cobrar transpar√™ncia, mostrar que √© sist√™mico, etc."
    )

    tamanho = st.selectbox(
        "Tamanho padr√£o",
        ["curto", "medio", "longo"],
        index=["curto","medio","longo"].index(profile.get("tamanho_padrao","medio"))
    )

    if st.button("Salvar diretrizes"):
        profile = {
            "nome_portal": nome_portal,
            "assinatura": assinatura,
            "estilo": estilo,
            "intencao_comunicativa": intencao,
            "tamanho_padrao": tamanho,
            "linhas": linhas
        }
        save_profile(profile)
        st.success("Diretrizes salvas. Vamos l√°! ‚úÖ")

# ---------- TAB 2: RADAR ----------
with tabs[1]:
    st.subheader("Intelig√™ncia de Curadoria")

    with st.expander("Fontes (RSS) e Palavras-chave", expanded=False):
        st.write("Fontes ativas:")
        for nome, url in list(st.session_state.sites.items()):
            st.write(f"‚Ä¢ {nome} ‚Äî {url}")

        st.write("Pesos atuais:")
        st.write(st.session_state.palavras)

    if st.button("Vamos l√° üöÄ Executar varredura editorial"):
        resultados = []
        for nome, url in st.session_state.sites.items():
            feed = feedparser.parse(url)
            for entry in feed.entries[:10]:
                texto = (entry.title + " " + entry.get("summary", "")).lower()
                score = 0
                for palavra, peso in st.session_state.palavras.items():
                    if palavra.lower() in texto:
                        score += peso
                resultados.append({
                    "fonte": nome,
                    "titulo": entry.title,
                    "link": entry.link,
                    "resumo": entry.get("summary", ""),
                    "score": score
                })

        df = pd.DataFrame(resultados)
        if not df.empty:
            df = df.sort_values(by="score", ascending=False)
            st.session_state.ultimo_df = df
            st.success("Varredura conclu√≠da. Ranking atualizado ‚úÖ")
            st.dataframe(df.head(12))
        else:
            st.warning("Nenhum resultado encontrado nas fontes atuais.")

    st.divider()
    st.subheader("Radar Editorial (tend√™ncia)")
    if st.session_state.ultimo_df is not None:
        texto_geral = " ".join((st.session_state.ultimo_df["titulo"].fillna("") + " " + st.session_state.ultimo_df["resumo"].fillna("")).tolist()).lower()
        cont = Counter()
        for palavra in st.session_state.palavras.keys():
            if palavra.lower() in texto_geral:
                cont[palavra] += texto_geral.count(palavra.lower())
        if cont:
            dominante = cont.most_common(1)[0][0]
            st.info(f"Tend√™ncia dominante (pelas suas palavras): {dominante}")
        else:
            st.info("Sem tend√™ncia clara pelas palavras configuradas (isso pode ser bom).")
    else:
        st.caption("Execute a varredura para ver tend√™ncias.")

# ---------- TAB 3: PRODU√á√ÉO (OpenAI) ----------
with tabs[2]:
    st.subheader("Produ√ß√£o Editorial")

    api_key = st.secrets.get("OPENAI_API_KEY", None)
    if not api_key:
        st.error("Chave de IA n√£o configurada (OPENAI_API_KEY em Secrets).")
        st.stop()

    # Limite simples (prote√ß√£o b√°sica)
    if "gen_count" not in st.session_state:
        st.session_state.gen_count = 0
    MAX_GEN_SESSION = 10

    if st.session_state.ultimo_df is None or st.session_state.ultimo_df.empty:
        st.warning("Primeiro execute a varredura na aba Intelig√™ncia.")
        st.stop()

    df = st.session_state.ultimo_df.head(20).reset_index(drop=True)
    escolha = st.selectbox("Escolha uma mat√©ria do ranking", options=list(range(len(df))), format_func=lambda i: f"{df.loc[i,'titulo']} ({df.loc[i,'fonte']})")

    formato = st.selectbox("Formato de sa√≠da", ["T√≠tulo + Lide", "T√≠tulo + Lide + 1¬∫ par√°grafo", "Legenda Instagram (curta)"])
    social_link = st.text_input("Link social (opcional, s√≥ refer√™ncia)", placeholder="Cole um link de post, se quiser")
    social_texto = st.text_area("Texto do post (opcional, recomendado se quiser reaproveitar)", height=90)

if st.button("Gerar texto com IA ‚úçÔ∏è"):

    # üîí Verificar limite di√°rio
    uso = verificar_limite_diario()

    if uso["contador"] >= MAX_DIARIO:
        st.error("Limite di√°rio de gera√ß√µes atingido (3 por dia). Tente amanh√£.")
        st.stop()

    materia = df.loc[escolha].to_dict()

    regras_seguranca = (
        "Regras: n√£o afirme acusa√ß√µes como fato sem atribui√ß√£o. "
        "Use 'segundo a mat√©ria', 'de acordo com', 'a investiga√ß√£o apura' quando houver alega√ß√µes. "
        "Evite difama√ß√£o. Mantenha linguagem respons√°vel."
    )

    instrucao = f"""
Voc√™ √© um redator para o portal "{profile.get('nome_portal')}".
Assinatura: "{profile.get('assinatura')}".
Estilo: {profile.get('estilo')}.
Inten√ß√£o comunicativa: {profile.get('intencao_comunicativa')}.
Tamanho: {profile.get('tamanho_padrao')} com cerca de {profile.get('linhas')} linhas.
Formato solicitado: {formato}.
{regras_seguranca}

Base (mat√©ria):
T√≠tulo: {materia.get('titulo')}
Fonte: {materia.get('fonte')}
Link: {materia.get('link')}
Resumo: {materia.get('resumo')}

Insumo social (se houver):
Link: {social_link}
Texto: {social_texto}
"""

    client = OpenAI(api_key=api_key)
    resp = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[
            {"role": "system", "content": "Voc√™ escreve textos jornal√≠sticos e conte√∫dos para redes sociais em PT-BR."},
            {"role": "user", "content": instrucao}
        ],
        temperature=0.7
    )

    uso["contador"] += 1
    salvar_uso(uso)

    st.success("Gerado ‚úÖ")
    st.text_area("Resultado", value=resp.choices[0].message.content, height=260)
    st.caption(f"Gera√ß√µes hoje: {uso['contador']}/3")
