import json
import re
import uuid
import datetime as dt
from datetime import datetime, timezone
from zoneinfo import ZoneInfo
from collections import Counter

import streamlit as st
import feedparser
import pandas as pd
from google import genai  # ‚úÖ SDK novo: google-genai

# ==============================
# CONFIG
# ==============================

st.set_page_config(page_title="Radar de Not√≠cias", layout="centered")

BRT = ZoneInfo("America/Fortaleza")

PROFILE_FILE = "perfil.json"
USO_FILE = "uso_ia.json"
AGENDA_FILE = "agenda.json"
PUBLICACOES_FILE = "publicacoes.json"

MAX_DIARIO = 3

EDITORIAIS = ["livre", "Pol√≠tica", "Economia", "Esporte", "Moda", "Cultura", "Educa√ß√£o", "Seguran√ßa", "Sa√∫de"]

PALAVRAS_TEMA = {
    "Pol√≠tica": ["governo", "congresso", "prefeitura", "vereador", "deputado", "ministro", "partido", "elei√ß√£o"],
    "Economia": ["infla√ß√£o", "juros", "pib", "mercado", "emprego", "renda", "investimento"],
    "Esporte": ["campeonato", "time", "atleta", "partida", "vit√≥ria", "gol", "copa"],
    "Moda": ["cole√ß√£o", "tend√™ncia", "look", "desfile", "marca", "estilo"],
    "Cultura": ["show", "festival", "arte", "cinema", "teatro", "livro"],
    "Educa√ß√£o": ["escola", "professor", "aluno", "enem", "universidade", "curso"],
    "Seguran√ßa": ["pol√≠cia", "crime", "assalto", "roubo", "pris√£o", "investiga√ß√£o"],
    "Sa√∫de": ["hospital", "sus", "vacina", "doen√ßa", "m√©dico", "tratamento"],
}

STOPWORDS_PT = {
    "a", "o", "os", "as", "de", "da", "do", "das", "dos", "em", "no", "na", "nos", "nas",
    "para", "por", "com", "sem", "um", "uma", "uns", "umas", "e", "ou", "ao", "aos", "√†",
    "√†s", "que", "se", "sua", "seu", "suas", "seus", "s√£o", "ser", "foi", "√©", "vai", "j√°",
    "mais", "menos", "entre", "sobre", "contra", "ap√≥s", "antes", "durante", "at√©", "isso",
    "essa", "esse", "este", "esta", "esses", "essas", "como", "quando", "onde", "porque",
    "pra", "pela", "pelo", "pelas", "pelos",
}

# ==============================
# JSON helpers
# ==============================

def read_json(path, default):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return default

def write_json(path, data):
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ==============================
# Profile / usage
# ==============================

def load_profile():
    return read_json(PROFILE_FILE, {
        "nome_portal": "Radar de Not√≠cias",
        "nome_redator": "Jos√© Nery",
        "assinatura": "jcsnery.empresa",
        "estilo": "jornalistico",
        "linhas": 10,
        "intencao_comunicativa": "neutro",
    })

def save_profile(p):
    write_json(PROFILE_FILE, p)

def carregar_uso():
    return read_json(USO_FILE, {"data": str(dt.date.today()), "contador": 0})

def salvar_uso(dados):
    write_json(USO_FILE, dados)

def verificar_limite():
    uso = carregar_uso()
    hoje = str(dt.date.today())
    if uso.get("data") != hoje:
        uso = {"data": hoje, "contador": 0}
        salvar_uso(uso)
    return uso

# ==============================
# Agenda / publica√ß√µes
# ==============================

def load_agenda():
    return read_json(AGENDA_FILE, {"itens": []})

def save_agenda(agenda):
    write_json(AGENDA_FILE, agenda)

def load_publicacoes():
    return read_json(PUBLICACOES_FILE, {"itens": []})

def save_publicacoes(pub):
    write_json(PUBLICACOES_FILE, pub)

# ==============================
# Text helpers
# ==============================

def normalizar_locais(txt: str):
    return [x.strip() for x in (txt or "").split(",") if x.strip()]

def extrair_data_entry(entry):
    if getattr(entry, "published_parsed", None):
        dtu = datetime(*entry.published_parsed[:6], tzinfo=timezone.utc)
        return dtu.astimezone(BRT)
    if getattr(entry, "updated_parsed", None):
        dtu = datetime(*entry.updated_parsed[:6], tzinfo=timezone.utc)
        return dtu.astimezone(BRT)
    return None

def marcador_tempo(dt_item, agora):
    if dt_item is None:
        return "SEM DATA"
    delta = agora - dt_item
    horas = delta.total_seconds() / 3600
    dias = delta.days
    if horas < 2:
        return "AGORA"
    if horas < 24:
        return "HOJE"
    if dias == 1:
        return "ONTEM"
    if dias < 7:
        return f"{dias} dias"
    if dias < 30:
        return f"{dias // 7} sem"
    return f"{dias // 30} mes"

def tokenize(texto: str):
    texto = (texto or "").lower()
    texto = re.sub(r"[^a-z√†-√∫0-9\s-]", " ", texto)
    parts = [p.strip() for p in texto.split() if p.strip()]
    out = []
    for p in parts:
        if len(p) < 3:
            continue
        if p in STOPWORDS_PT:
            continue
        out.append(p)
    return out

def score_texto(texto: str, palavras: list[str], locais: list[str]):
    t = (texto or "").lower()
    sc = 0
    for w in palavras:
        if w and w.lower() in t:
            sc += 2
    for loc in locais:
        if loc and loc.lower() in t:
            sc += 4
    return sc

def montar_google_news_url(assunto: str, local: str, janela: str):
    consulta = " ".join([x for x in [assunto.strip(), local.strip()] if x]).strip()
    if not consulta:
        consulta = "not√≠cias"

    when_map = {"24h": "1d", "7 dias": "7d", "30 dias": "30d"}
    when = when_map.get(janela)
    if when:
        consulta = f"{consulta} when:{when}"

    q = consulta.replace(" ", "+")
    return f"https://news.google.com/rss/search?q={q}&hl=pt-BR&gl=BR&ceid=BR:pt-419"

# ==============================
# Gemini (SDK novo: google-genai)
# ==============================

def gemini_generate(prompt: str, temperature: float = 0.7, max_output_tokens: int = 900) -> str:
    api_key = st.secrets.get("GEMINI_API_KEY", None)
    if not api_key:
        raise RuntimeError("Chave GEMINI_API_KEY n√£o configurada.")

    client = genai.Client(api_key=api_key)
    
    resp = client.models.generate_content(
        model="gemini-1.5-flash",
        contents=prompt,
        config={
            "temperature": float(temperature),
            "max_output_tokens": int(max_output_tokens),
        },
    )

    texto = (getattr(resp, "text", "") or "").strip()
    if not texto:
        raise RuntimeError("A IA n√£o retornou texto.")
    return texto

# ==============================
# UI
# ==============================

profile = load_profile()

st.title("üì° Radar de Not√≠cias")
st.caption(f"{profile['nome_portal']} ‚Ä¢ {profile.get('assinatura','jcsnery.empresa')}")

tabs = st.tabs(["Radar", "Reda√ß√£o", "Perfil"])

# ------------------------------
# PERFIL
# ------------------------------
with tabs[2]:
    st.subheader("Perfil editorial")

    nome_portal = st.text_input("Nome do Portal", value=profile.get("nome_portal", "Radar de Not√≠cias"))
    nome_redator = st.text_input("Nome do Redator", value=profile.get("nome_redator", ""))
    estilo = st.selectbox(
        "Estilo de Escrita",
        ["jornalistico", "analitico", "opinativo", "didatico"],
        index=["jornalistico", "analitico", "opinativo", "didatico"].index(profile.get("estilo", "jornalistico"))
    )
    linhas = st.slider("Quantidade de linhas de Reda√ß√£o", 4, 20, int(profile.get("linhas", 10)))
    intencao = st.text_area("Inten√ß√£o comunicativa", value=profile.get("intencao_comunicativa", ""))

    if st.button("Salvar Perfil"):
        save_profile({
            "nome_portal": nome_portal,
            "nome_redator": nome_redator,
            "assinatura": profile.get("assinatura", "jcsnery.empresa"),
            "estilo": estilo,
            "linhas": linhas,
            "intencao_comunicativa": intencao,
        })
        st.success("Perfil salvo.")

# ------------------------------
# RADAR (somente busca global)
# ------------------------------
with tabs[0]:
    st.subheader("Radar")

    colA, colB = st.columns(2)
    with colA:
        editorial = st.selectbox("Editorial", EDITORIAIS, index=0)
        janela = st.selectbox("Janela de tempo", ["24h", "7 dias", "30 dias"], index=0)
        local = st.text_input("Local", placeholder="Brasil, RN, Natal, Groenl√¢ndia‚Ä¶")
    with colB:
        st.markdown("### Palavras em alta")
        palavras_box = st.empty()
        st.markdown("### Assuntos")
        assuntos_box = st.empty()

    itens_por_fonte = st.slider("Itens por fonte", 5, 30, 10)

    # Guia de publica√ß√µes (MVP)
    st.markdown("### Guia de Publica√ß√µes")
    agenda = load_agenda()
    feitas = [x for x in agenda["itens"] if x.get("status") == "feita"]
    a_fazer = [x for x in agenda["itens"] if x.get("status") != "feita"]

    c1, c2 = st.columns(2)
    with c1:
        st.markdown("**Feitas**")
        if feitas:
            for it in sorted(feitas, key=lambda x: (x.get("data", ""), x.get("hora", "")))[-3:]:
                st.caption(f"{it.get('data','')} {it.get('hora','')} ‚Ä¢ {it.get('titulo','')} ‚Ä¢ {it.get('canal','')}")
        else:
            st.caption("‚Äî")
    with c2:
        st.markdown("**A fazer**")
        if a_fazer:
            for it in sorted(a_fazer, key=lambda x: (x.get("data", ""), x.get("hora", "")))[:3]:
                st.caption(f"{it.get('data','')} {it.get('hora','')} ‚Ä¢ {it.get('titulo','')} ‚Ä¢ {it.get('canal','')}")
        else:
            st.caption("‚Äî")

    st.divider()

    assunto_livre = st.text_input("Assunto", placeholder="Ex: picol√©s, dengue, emprego‚Ä¶ (deixe livre se usar Editorial)")

    if st.button("Buscar not√≠cias"):
        agora = datetime.now(BRT)
        locais_norm = normalizar_locais(local)

        # palavras para score
        if editorial != "livre":
            palavras = PALAVRAS_TEMA.get(editorial, [])
            assunto_busca = assunto_livre.strip() or editorial
        else:
            palavras = tokenize(assunto_livre)[:10]
            assunto_busca = assunto_livre.strip() or "not√≠cias"

        url = montar_google_news_url(assunto_busca, local, janela)
        feed = feedparser.parse(url)

        resultados = []
        for entry in feed.entries[:itens_por_fonte]:
            titulo = getattr(entry, "title", "").strip()
            link = getattr(entry, "link", "").strip()
            resumo = entry.get("summary", "") or ""
            dt_item = extrair_data_entry(entry)

            base = f"{titulo} {resumo}"
            sc = score_texto(base, palavras, locais_norm)

            resultados.append({
                "quando": marcador_tempo(dt_item, agora),
                "data_txt": dt_item.strftime("%d %b %Y ‚Ä¢ %H:%M (BRT)") if dt_item else "data n√£o informada pela fonte",
                "data": dt_item,
                "fonte": "Google News",
                "titulo": titulo,
                "link": link,
                "resumo": resumo,
                "score": sc,
            })

        df = pd.DataFrame(resultados)
        if df.empty:
            st.warning("Nenhum resultado encontrado.")
            st.session_state.pop("ranking", None)
        else:
            df["data_ord"] = pd.to_datetime(df["data"], utc=True, errors="coerce")
            df["data_ord"] = df["data_ord"].fillna(pd.Timestamp("1970-01-01", tz="UTC"))
            df = df.sort_values(["score", "data_ord"], ascending=[False, False]).reset_index(drop=True)

            st.session_state["ranking"] = df

            # Palavras em alta
            tokens = []
            for _, r in df.head(30).iterrows():
                tokens.extend(tokenize(r.get("titulo", "")))
            top = [w for w, _ in Counter(tokens).most_common(8)]
            palavras_box.info("\n".join([w.upper() for w in top]) if top else "‚Äî")

            # Assuntos (top t√≠tulos)
            assuntos = [r.get("titulo", "") for _, r in df.head(5).iterrows()]
            assuntos_box.info("\n".join(assuntos) if assuntos else "‚Äî")

            st.dataframe(df[["quando", "data_txt", "fonte", "titulo", "score", "link"]].head(15), use_container_width=True)

# ------------------------------
# REDA√á√ÉO
# ------------------------------
with tabs[1]:
    st.subheader("Reda√ß√£o")

    pub = load_publicacoes()
    if pub["itens"]:
        st.markdown("**√öltimas publica√ß√µes**")
        for it in pub["itens"][-3:][::-1]:
            st.caption(f"{it.get('data','')} ‚Ä¢ {it.get('titulo','')}")

    st.divider()

    if "ranking" not in st.session_state or st.session_state["ranking"].empty:
        st.warning("Busque not√≠cias no Radar antes.")
        st.stop()

    df = st.session_state["ranking"]

    escolha = st.selectbox(
        "Escolha a mat√©ria",
        range(len(df)),
        format_func=lambda i: f"{df.iloc[i]['quando']} ‚Ä¢ {df.iloc[i]['titulo']}"
    )

    materia = df.iloc[escolha]
    st.caption(f"üóìÔ∏è {materia['data_txt']} | üì∞ {materia['fonte']}")

    col1, col2, col3 = st.columns(3)
    with col1:
        canal = st.selectbox("Canal", ["Instagram", "Facebook", "WhatsApp", "Site"])
    with col2:
        data_post = st.date_input("Data", value=dt.date.today())
    with col3:
        hora_post = st.time_input("Hora", value=dt.time(18, 0))

    uso = verificar_limite()
    st.caption(f"Limite di√°rio: {uso['contador']}/{MAX_DIARIO}")

    if st.button("Gerar publica√ß√£o"):
        uso = verificar_limite()
        if uso["contador"] >= MAX_DIARIO:
            st.error("Limite di√°rio atingido.")
            st.stop()

        prompt = f"""
Voc√™ √© redator do portal {profile['nome_portal']}.
Autor/assinatura: {profile.get('nome_redator','')} ‚Ä¢ {profile.get('assinatura','')}
Estilo: {profile['estilo']}
Inten√ß√£o: {profile['intencao_comunicativa']}
Tamanho: ~{profile['linhas']} linhas.

Base (not√≠cia):
Fonte: {materia['fonte']}
Data: {materia['data_txt']}
T√≠tulo: {materia['titulo']}
Resumo: {materia['resumo']}
Link: {materia['link']}

Entrega:
- Texto pronto para publica√ß√£o no canal: {canal}
- Linguagem PT-BR
- N√£o invente fatos al√©m do que est√° na base.
- Se a base for insuficiente, deixe claro que √© um resumo a partir do feed.
"""

        try:
            texto = gemini_generate(prompt, temperature=0.7, max_output_tokens=900)

            # registra uso
            uso["contador"] += 1
            salvar_uso(uso)

            # salva publica√ß√£o
            pub = load_publicacoes()
            pub["itens"].append({
                "id": str(uuid.uuid4()),
                "data": datetime.now(BRT).strftime("%d/%m/%Y %H:%M"),
                "titulo": materia["titulo"],
                "texto": texto,
                "fonte": materia["fonte"],
                "link": materia["link"],
                "canal": canal,
            })
            save_publicacoes(pub)

            # adiciona ao planner
            agenda = load_agenda()
            agenda["itens"].append({
                "id": str(uuid.uuid4()),
                "data": data_post.strftime("%d/%m/%Y"),
                "hora": hora_post.strftime("%H:%M"),
                "titulo": materia["titulo"][:110],
                "canal": canal,
                "status": "a_fazer",
            })
            save_agenda(agenda)

            st.success("Publica√ß√£o gerada e adicionada ao planner.")
            st.text_area("Resultado", texto, height=320)

        except Exception as e:
            st.error("Erro ao gerar com Gemini.")
            st.exception(e)
